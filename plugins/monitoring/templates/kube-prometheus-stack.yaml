# https://github.com/prometheus-operator/prometheus-operator/tree/main/helm
# https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-node-exporter
# https://artifacthub.io/packages/helm/banzaicloud-stable/grafana-operator
# https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics
apiVersion: plugins.kubegems.io/v1beta1
kind: Plugin
metadata:
  name: kube-prometheus-stack
  namespace: {{ .Release.Namespace }}
spec:
  kind: helm
  url: https://prometheus-community.github.io/helm-charts
  version: {{ .Chart.AppVersion }}
  values:
    global:
      rbac:
        createAggregateClusterRoles: true
    defaultRules:
      create: false
    kube-state-metrics:
      image:
        # repository: k8s.gcr.io/kube-state-metrics/kube-state-metrics
        {{ include "common.images.repository" ( dict "registry" "k8s.gcr.io" "repository" "kube-state-metrics/kube-state-metrics" "context" .) }}
      metricAnnotationsAllowList:
      - pods=[pai.kubegems.io/sku-raw-name,volcano.sh/queue-name,pai.kubegems.io/creator]
      - persistentvolumeclaims=[pai.kubegems.io/creator]
      metricLabelsAllowlist:
      - namespaces=[*]
      - pods=[pai.kubegems.io/job-name,pai.kubegems.io/tenant]
      - persistentvolumeclaims=[pai.kubegems.io/storageset-kind,pai.kubegems.io/tenant]
      prometheus:
        monitor:
          metricRelabelings:
            # drop this becase it has label service_name, which affect otel dashboard variables
            - sourceLabels: [__name__]
              regex: kube_(ingress_path|persistentvolume_status_phase|pod_tolerations|pod_status_reason|pod_status_scheduled|pod_status_ready|persistentvolumeclaim_status_phase|configmap|_persistentvolumeclaim_status_phase).*
              action: drop
    grafana:
      enabled: false
    prometheusOperator:
      tls:
        enabled: false
      admissionWebhooks:
        enabled: false
      image:
          # registry: quay.io
          # repository: prometheus-operator/prometheus-operator
        {{ include "common.images.registry" . }}
        {{ include "common.images.repository" ( dict "repository" "prometheus-operator/prometheus-operator" "context" .) }}
      prometheusConfigReloader:
        image:
          # registry: quay.io
          # repository: prometheus-operator/prometheus-config-reloader
          {{ include "common.images.registry" . }}
          {{ include "common.images.repository" ( dict "repository" "prometheus-operator/prometheus-config-reloader" "context" .) }}
    prometheus:
      prometheusSpec:
        image:
          # registry: quay.io
          # repository: prometheus/prometheus
          {{ include "common.images.registry" . }}
          {{ include "common.images.repository" ( dict "repository" "prometheus/prometheus" "context" .) }}
        enableAdminAPI: true
        enableFeatures: 
          - remote-write-receiver
        externalLabels:
          cluster: {{ .Values.global.clusterName }}
        # TODO: use correct port when we can get default-gateway's nodeport
        externalUrl: http://{{ .Values.prometheus.externalHost }}:{{ .Values.prometheus.externalPort }}
        ruleSelector:
          matchExpressions:
            - key: prometheusrule.kubegems.io/name
              operator: Exists
        probeSelectorNilUsesHelmValues: false
        retention: {{ .Values.prometheus.retention }}
        resources:
          limits:
            cpu: {{ .Values.prometheus.maxCpu }}
            memory: {{ .Values.prometheus.maxMemory }}
          requests:
            cpu: 100m
            memory: 128Mi
        storageSpec:
          volumeClaimTemplate:
            spec:
              accessModes:
              - ReadWriteOnce
              storageClassName: {{ .Values.global.storageClass }}
              resources:
                requests:
                  storage: {{ .Values.prometheus.volumeCapacity }}
              volumeMode: Filesystem
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        {{- if .Values.prometheus.additionalScrapeConfigs }}
        additionalScrapeConfigs:
{{ toYaml .Values.prometheus.additionalScrapeConfigs | indent 10 }}
        {{- end }}
      additionalServiceMonitors:
        - name: kubegems-local-agent
          namespaceSelector:
            matchNames:
              - kubegems-local
          selector:
            matchLabels:
              app.kubernetes.io/name: kubegems-local
              app.kubernetes.io/component: agent
          endpoints:
            - path: /metrics
              port: metrics
              honorLabels: true
        - name: cert-manager
          namespaceSelector:
            matchNames:
              - cert-manager
          selector:
            matchLabels:
              app.kubernetes.io/name: cert-manager
              app.kubernetes.io/component: controller
          endpoints:
            - path: /metrics
              port: tcp-prometheus-servicemonitor
              honorLabels: true
      ingress:
        enabled: true
        ingressClassName: default-gateway
        labels:
          networking.kubegems.io/ingressClass: default-gateway        
        hosts: [{{ .Values.prometheus.externalHost }}]
    alertmanager:
      # templateFiles:
      alertmanagerSpec:
        image:
          # registry: quay.io
          # repository: prometheus/alertmanager
          {{ include "common.images.registry" . }}
          {{ include "common.images.repository" ( dict "repository" "prometheus/alertmanager" "context" .) }}
        alertmanagerConfigSelector:
          matchExpressions:
            - key: alertmanagerconfig.kubegems.io/name
              operator: Exists
        alertmanagerConfiguration:
          name: kubegems-default-monitor-alert-rule
          templates:
          - configMap:
              key: kubegems-email.tmpl
              name: kubegems-email-template
        # do not force add namespace label matcher
        alertmanagerConfigMatcherStrategy:
          type: None
        replicas: {{ .Values.alertmanager.replicas }}
        retention: {{ .Values.alertmanager.retention }}
        storage:
          volumeClaimTemplate:
            spec:
              accessModes:
              - ReadWriteOnce
              storageClassName: {{ .Values.global.storageClass }}
              resources:
                requests:
                  storage: {{ .Values.alertmanager.volumeCapacity }}
              volumeMode: Filesystem
        # TODO: use correct port when we can get default-gateway's nodeport
        externalUrl: http://{{ .Values.alertmanager.externalHost }}:{{ .Values.alertmanager.externalPort }}
        resources:
          limits:
            cpu: {{ .Values.alertmanager.maxCpu }}
            memory: {{ .Values.alertmanager.maxMemory }}
          requests:
            cpu: 50m
            memory: 64Mi
      ingress:
        enabled: true
        ingressClassName: default-gateway
        labels:
          networking.kubegems.io/ingressClass: default-gateway
        hosts: [{{ .Values.alertmanager.externalHost }}]
    nodeExporter:
      enabled: false
    # metrics
    kubeApiServer:
      serviceMonitor:
        metricRelabelings:
          - sourceLabels: [__name__]
            regex: apiserver_(admission|crd|watch_events)_(.*)
            action: drop
